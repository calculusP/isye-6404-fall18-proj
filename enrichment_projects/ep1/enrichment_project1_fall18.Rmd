---
title: 'Enrichment Project #1: Rank-based Methods'
author:
- Yuan Gao, Kevin Lee, Akshay Govindaraj
- Yijun (Emma) Wan, Peter Williams, Ruixuan Zhang
- ygao390, kylee20, ywan40, agovindaraj6, pwilliams60, rzhang438 | @gatech.edu
date: '2018-09-25'
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  word_document:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#suppressPackageStartupMessages(library(printr))
suppressPackageStartupMessages(library(conover.test))
suppressPackageStartupMessages(library(car))
suppressPackageStartupMessages(library(nortest))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(reshape2))
suppressPackageStartupMessages(library(car))
```

# 1) Two-sample Studies (40%):
*Locate a data set in the field of your interest, e.g., eCommerce, medical study, drug development, supply-chain/logistics operations, for applying the following procedures for two-sample studies.*  

For our two-sample study, we have selected a dataset published by the City of Chicago Transit Authority (CTA) that details daily ridership numbers (system-wide boarding totals) for both bus and rail services. As a pre-processing step, we take a subset of the original dataset that consists of weekday ridership only (weekends, and holidays excluded) for 2017 and 2018. Below is a quick preview of the dataset and pre-processing steps: 
```{r preview, include=T, echo=F}
rider_data <- read.csv(
  'data/CTA_Ridership_Normalized.csv',
                       header = T,stringsAsFactors = F)
#subset data to just weekdays
rider_data <- rider_data[rider_data$day_type == 'W',]
rider_data <- transform(rider_data, service_date = as.Date(service_date, 
                                                           '%m/%d/%y'))
#subset data to 2017 and 2018 rides only
rider_data <- rider_data[format(rider_data$service_date, '%Y') %in% 
                           c('2017','2018'),]
knitr::kable(head(rider_data,n=5),row.names = F, format.args = list(big.mark = ','))
```
  
  
Note: For the purpose of comparison, we transformed the data to normalize the distributions for equal variances between them. This will allow us to perform both nonparametric and parametric tests to determine whether the two sample distributions are different. The variances of the samples were unequal, so we cannot nonparametric tests such as the Wilcoxon Rank Sum Test. With our new data, the variances are close enough that the distributions can then be compared. 

## Bootstrap Re-sampling

*1. Calculate Pearson and Spearman coefficient of correlation and Kendall’s Tau. Use a Bootstrap resampling procedure with B = #bootstrap-samples = 1000 to assess the standard deviation (sd) of three estimates. Comment on your findings.*  

To begin we compute all three statistics using methods in base R, reported here: 
```{r correl, include=T,echo=F}
paste0("Pearson's Correlation: " ,round(with(rider_data, cor(x=bus,y=rail_boardings,
                                                             method = "pearson")),digits=3))
paste0("Spearman's Correlation: " ,round(with(rider_data, cor(x=bus,y=rail_boardings,
                                                              method = "spearman")),digits=3))
paste0("Kendall's Tau: " ,round(with(rider_data, cor(x=bus,y=rail_boardings,
                                                     method = "kendall")),digits=3))
```
We then compute these statistics using $B=1000$ bootstrap samples based on our original dataset, which consists of `r nrow(rider_data)` observations. Code and details are below. As shown in the table of results, bootstrap sample standard deviations for all correlation statistics were similar, and were slightly higher for spearman's rank:  
```{r bstrap, include=T,echo=T, height = 4}
#set the number of bootstrap samples (with replacement - n = 318)
B <- 1000
#replicate process of collecting sample from original dataset, and compute sample stats 
#results stored in: cor_result, with 1000 obs of bootstrap sample stats
#note this process takes a few seconds on a standard laptop
cor_result <- do.call('rbind',lapply(1:B, function(x){
  bootstrap_sample <- rider_data[sample(1:nrow(rider_data),
                                        size=nrow(rider_data), replace=T),]
  data.frame(pearson = cor(bootstrap_sample$bus,bootstrap_sample$rail_boardings, 
                           method = 'pearson'),
             spearman = cor(bootstrap_sample$bus,bootstrap_sample$rail_boardings, 
                            method = 'spearman'),
             kendall = cor(bootstrap_sample$bus,bootstrap_sample$rail_boardings, 
                           method = 'kendall'))
}))
knitr::kable(round(data.frame(lapply(cor_result, sd)),digits=4),row.names=F,
             caption = 'Sample Standard Deviation: Bootstrap Sample Correlation')
```

Density plots of these statistics are shown here, and provide visual evidence that the spearman rank correlation results and kendall's tau have more similar results than the parametric pearson's correlation: 

```{r den_cor, include=T,echo=T,fig.align = 'center',fig.height = 3}
melt_cor_result <- melt(cor_result, measure.vars = c('pearson','spearman','kendall'))
ggplot(melt_cor_result, aes(x = value, fill = variable)) + geom_density(alpha = 0.3) + theme_bw() + 
  xlab('Boostrap Sample Correlation') + ggtitle('Density Plots: Bootstrap Sample Correlations')
```
  
## Signed Rank Tests
*2. Apply Wilcoxon Signed Rank Test, Wilcoxon Sum Rank Test, Mann-Whitney U Test to compare two samples. For each test please state clearly what distribution is used to calculate the p-value.*  

Continuing on with the data given by the CTA on bus and rail ridership in 2017 and 2018, we can attempt to utilize the Wilcoxon Signed-Rank Test to determine whether there is a difference between paired data, but certain assumptions must first be met. In using the Wilcoxon Signed Rank Test, the data must be paired, the pairs must be independent, and the paired differences must be distributed symmetrically about 0 (the assumption that the pairs are drawn from the same population). The samples would also be better if from a nonnormal distribution (comparable parametric tests are more reliable only if data are normally distributed). 

The Signed Rank Test (for two samples) looks at the difference in distributions between paired values, and our data are not paired in this case. Instead, the better test to use in the case of our CTA data would be the Wilcoxon Ranked Sum Test. The goal of the Wilcoxon Ranked Sum Test is to effectively compare two populations with a continuous response variable and nonnormal distributions. Thus, the Wilcoxon Ranked Sum Test is essentially analagous to a nonparametric form of a two sample t-test. Assuming the ridership count between the bus and rail systems are independent of each other and random, we can compare the two samples using the Wilcoxon Ranked Sum Test even without the assumption of paired data as was required in the Wilcoxon Signed Rank Test. 

The Mann Whitney U Test accomplishes essentially the exact same purpose as the Wilcoxon Ranked Sum Test. The only differences are a differently labeled test statistic "U" compared to that of the Wilcoxon ranked sum test statistics "W" as well as the assumption that the shapes of the two population distributions have the same "shape". They are even performed using the exact same function, with the "U" test statistic being equivalent to the "W" test statistics of the Wilcoxson Ranked Sum Test.

```{r histograms_non_normal, echo = T, include = F, fig.align='center',fig.height=3}
#Checking that the distribution of each of the two samples is nonnormal
melted_rider_data <- melt(rider_data, measure.vars = c('bus','rail_boardings'), 
                          id.vars = 'service_date')
melted_rider_data <- transform(melted_rider_data, 
                               variable = ifelse(as.character(variable) == 'rail_boardings','Rail','Bus'))
ggplot(melted_rider_data, aes(x = value/1e06, fill = variable)) + 
    geom_density(alpha = 0.3) + theme_bw() + 
      xlab('Daily Ridership') + ggtitle('Density Plots: Daily Boardings by Type (mms)')
```

If we plot the density, we can see the distributions seem to resemble normal distributions, and they do resemble each other in terms of their "shape". 

```{r wilcox_rank, echo = T, include = T}
#Performing the Wilcoxon Rank Sum Test/Mann Whitney U Test
with(rider_data, wilcox.test(bus,rail_boardings, paired=F))
```

The results of the Wilcoxon Ranked Sum Test show the p-value of the test to be small enough to be significant, meaning we reject the null hypothesis that the distributions of the two samples are identical. The fact that the Wilcoxon Ranked Sum Test and the Mann Whitney U Test are essentially the same test allows us to also state that the medians of the two distributions are also different. 

For the calculation of the p-value, one must first be able to determine the test statistic being used in each test. For the Wilcoxon Rank Sum test, we find the 

$$W_{n} = \sum^{n}_{i=1}iS_{i}(X,Y)$$

where $n_1$ is the sample size of the first sample (observations in bus ridership) , $n_2$ is the sample size of the second sample (observations in rail boarding), and $n_1 + n_2 = n$

$S_{i}$ is an indicator function with value is 1 if ith ranked observation is from the first sample or 0 if from the second sample.
[cite textbook]

The expected value of the $W_n$ statistic is where the distrition will be centered around, and the variance of the statistic will be the symmetrical spread around that center: 

$$E(W_{n}) = [n_{1}(n+1)]/2$$

$$Var(W_{n}) = [n_{1}n_{2}(n+1)]/12$$

As the test statistic is a linear rank statistic, we can then deduce that the W statistic is distributed approximately normally as long as the sample sizes are large enough (at least 10 observations per sample). We can then calculate the right-tail probability using Z-score with normal approximation with the following distribution:

$$W_{n} \sim N([n_1 (n+1)]/2 , [n_1 (n_2) (n+1)]/12)$$

The Mann-Whitney U statistic is used to calculate p-value much in the same manner of the Wilcoxon Rank Sum Test. The test statistic can be calculated as such: 

$$U = \sum^{n1}_{i=1}\sum^{n2}_{j=1} D_{ij}$$

The test statisic U and W end up becoming the same value, used in the same approximately normal distribution as the $W_{n}$ statistic, which means we can use the same tail probability to find the p-value.

In order to apply the Wilcoxon Signed-Rank Test, we will need to use a different set of data to demonstrate the test in R. For this purpose, we will use the data from this site:  https://www.sheffield.ac.uk/polopoly_fs/1.569449!/file/stcp-Rdataset-Video.csv.  

A professor at the University of Sheffield collected data using "Likert" style questions to determine which of three new videos are most effective in informing the public of medical conditions. The four videos in questions are deemed the following: A, a new general video; B, a new medical profession video; C, the old video; and D, a demonstration using props. In this dataset, there are two particular variables of interest, and they are "TotalAGen" and "TotalDDEMO". These two variables are essentially the overall summed "Likert Scores" for each of the different types of videos. Our paired data will be between the scaled overall scores between video A's reception  and video D's reception. 

``` {r sign_rank, echo = F, include= T, fig.align='center',fig.height=3}
#For performing the Wilcoxon Signed Rank Test, download the dataset
video_data=read.csv('data/sheffield_video_data.csv',header=T)
#Wilcoxon Signed Rank Test, with paired data
suppressWarnings(wilcox.test(video_data$TotalAGen,video_data$TotalDDEMO, paired=T))
#Showing nonnormal distributions of the sample data
melted_video_data <- melt(video_data[,c('TotalAGen','TotalDDEMO')], measure.vars = c('TotalAGen','TotalDDEMO'))

ggplot(melted_video_data, aes(x = value, fill = variable)) + 
  geom_density(alpha = 0.3) + theme_bw() + 
    xlab('Summed Likert Scores') + ggtitle('Density Plots: Video Types {A, D}')

#original base plot
# par(mfrow = c(1,2))
# hist(video_data$TotalAGen, xlab ="TotalAGen" , ylab = "Count" , main ="Histogram: Video TotalAGen" , bty = 'n')
# hist(video_data$TotalDDEMO, xlab = "TotalDDEMO", ylab = "Count",main = "Histogram: Video TotalDDemo", bty='n')
```

We can assume the independence of each observation (person) as well as the fact that they should come from the same population (differences should be symmetric about 0). The data are also paired, so we can follow through with the test now that the assumptions are met. Through the Wilcoxon Signed Rank Test, we can see that the test statistic V = 167.5, which leads us to a p-value below our assumed alpha level of 0.05. Thus, we can reject the null hypothesis that the two sample distributions (Scores of Video A compared to scores of Video D) are the same. 

The p-value of the signed rank test is based on a W test statistic and tabulated critical values when dealing with lower sample sizes, such that it can be calculated as follows: 

$$W = \sum^{n}_{i=1} sign(x_{2,i}-x_{1,i},|R_i|)$$

Where $R_i$ is the rank of the observation and the statistic is the formula for the sum of the signed ranks. With this test statistic, one can determine a distribution with 

$$E(W) = 0$$
$$Var(T) = [n(n+1)(2n+1)/6]$$ 

where n is the number of non-tied ranked observations. With this information, one can look at a table of set critical values dependent on sample size and quantiles with which to determine whether or not to reject the hypothesis that the

With larger sample sizes though, the distribution of the W statistic for the signed rank test also tends to follow normal approximation, which allows the use of z-score approximation to determine p-value through tail probability.


## Fligner Test for Equal Variances
*3. Use Fligner test for equal variances in these two samples. Explain how to calculate its p-value.*  

We again show a density plot that visualizes the counts of daily bus and rail ridership illustrating that variance of daily ridership seems homogenous across ride modality. Both ridership types also seems to be spread symmetrically around their central point as shown here: 

```{r histo, include = T, echo=F, fig.align='center',fig.height=3}
boardings <- c(rider_data$bus, rider_data$rail_boardings)
factor_level <- factor(c(rep('bus',nrow(rider_data)), rep('rail',nrow(rider_data))))
ggplot(melted_rider_data, aes(x = value/1e06, fill = variable)) + 
  geom_density(alpha = 0.3) + theme_bw() + 
    xlab('Daily Ridership') + ggtitle('Density Plots: Daily Boardings by Type (mms)')
```

To explore this further we utilize the Fligner test to test the hypothesis $H_0: \sigma^2_X = \sigma^2_Y$, where samples $X_1,...,X_{n1}$, and $Y_1,...,Y_{n_2}$ refer to samples from daily ridership of bus and rail. The output of the test utilizing the 'fligner.test' function from R (package::car) is shown below, where our chosen $\alpha = 0.05$:  

```{r conover, echo =F, include = T}
#alt = 0 -> test hypothesis sigma^2_x \neq sigma^2_y
fligner_test <- fligner.test(x = boardings, g = factor_level)
fligner_test
```
  
Since our test statistic $\chi_{K}^2* =$ `r round(fligner_test$statistic,digits=3)`, is less than (`r qchisq(0.95, df = fligner_test$parameter)`), we fail to reject our null hypothesis, that is $H_0: \sigma^2_X = \sigma^2_Y$. 

The calculation of p-value is based on our realized $\chi^2$ statistic which is computed by:
$$\chi_{K}^2* = \frac{\sum_{j=1}^{k}n_j(\bar{a_j} - \bar{a})^2}{V^2} $$
Where $k = \text{number of groups}$, $n_j$ is the number of observations for the $j^{th}$ group, $\bar{a_j}$ is the mean of the median centered, ranked, and subsequently normalized observations for the $j^{th}$ group. $\bar{a}$ is the mean of all median centered, ranked and normalized observations, and $V^2$ is the sample variance of the same normalized observations. If the assumptions are met, the distribution of this test statistic follows approximately the Chi-squared distribution with degrees of freedom $k-1$. We can use the Chi-square distribution to get the p-value of Fligner test given our realized sample statistic.

## Parametric F-test For Equal Variances

*4. Use the parametric F-test for equal variances to the data; comment on the difference of the assumptions and results compared to them in (iii).*  
F-test for testing equality of variance is used to test the hypothesis of the equality of two population X and Y's variances.
Let $A_1, ..., A_n$ and $B_1, ..., B_m$ be independent and identically distributed samples from two populations which each have a normal distribution where the expected values for the two populations can be different.
The test statistic can be obtained by computing the ratio of the two variances $S^2_A$ and $S^2_B$.
$${\displaystyle S_{A}^{2}={\frac {1}{n-1}}\sum _{i=1}^{n}\left(A_{i}-{\overline {A}}\right)^{2}{\text{  and  }}S_{B}^{2}={\frac {1}{m-1}}\sum _{i=1}^{m}\left(B_{i}-{\overline {B}}\right)^{2}}$$
$$F=\frac{S^2_A}{S^2_B}$$    
  
The degrees of freedom are $n_A - 1$ (for the numerator) and $n_B - 1$ (for the denominator). And, the more this ratio deviates from $1$, the stronger the evidence for unequal population variances.  

```{r test_var, echo = F, include = T}
var.test(rider_data$bus, rider_data$rail_boardings, alternative = "two.sided")
```
  
The result shows that the p-value $= 0.9422$ and the ratio $= 1.00818$ which is significantly greater than our $\alpha = 0.05$ and close to 1. In conclusion, we can accept our null hypothesis that the two data have the same variance.

Assumptions for Conover and F-test:

According to the deviration above,the F-test is known to be extremely sensitive to non-normality and F-tests for the equality of variances can be used in practice, with care, particularly where both graphical and formal checks of the assumption.We use Q-Q plot (quantile-quantile plot) to graphically evaluate the normality of a variable.  

```{r qqplots, echo = F, include = T, fig.align='center',fig.height=4}
#qqnorm(rider_data$bus, pch = 1, frame = FALSE)
#qqline(rider_data$bus, col = "steelblue", lwd = 2)
options(scipen = 999)
par(mfrow = c(1,2))
qqPlot(rider_data$bus, xlab = 'Bus Boardings',ylab  = 'Theoretical Quantiles' ,main = 'Q-Q Plot - Bus Boardings')
qqPlot(rider_data$rail, xlab = 'Rail Boardings',ylab  = 'Theoretical Quantiles' ,main = 'Q-Q Plot - Rail Boardings')
```

As we can see, Almost all the points fall into the reference line, for both rail and bus boardings, so, we can assume normality for either sample under Q-Q plot test. Therefore, we can use the F-test to test the equal variance of the two sample.

However, the Conover is a nonparametric test of homogeneity (equal variance) based on ranks. It computes the Conover-Iman test for stochastic dominance and gives the results among multiple pairwise comparisons. The test does not assume that all populations are normally distributed and is recommended when the normality assumption is not viable.

Results for Conover and F-test:
Although the results are consistent based on this sample, Conover test is recommended when the normality assumption is not viable.
As a result, use F-test on the data has shortcomings compared to use Conover test.  

## Parametric Two-Sample T-test

*5. Depending on the outcomes from the F-test in (iv), apply an appropriate parametric two- sample t-test to the data; comment on the difference of the assumptions and results compared to them in (ii).*  

The aim of the two-sample t-test is to find the difference between the two sample means in comparing their respective populations. In utilizing the two sample t-test, some assumptions must first be met. One must assume that the observations of our data are independent of each other, similar to the nonparametric tests. Another such assumption is for the response variable to be continuous, approximately normal distribution. Our normalized ridership data allows us to be able to perform the parametric (pooled) two sample t-test. Similar to the nonparametric tests performed (Mann-Whitney U), the data must be continuous. 

```{r t_test, include = T, echo = F}
#Performing Parametric t-test between the two samples, pooled t-test is used because the normalized data have equal variance.
t.test(rider_data$bus,rider_data$rail_boardings,var.equal=TRUE)
```
  
As we can see from the results of the test, the p-value is quite low, showing that there is a significant difference between the two means. In comparing the two tests, the parametric t-test tests for significance in difference between the means of the two samples, while the nonparametric tests (Mann-Whitney U) test for significance in differences between the distributions (and medians) of the two samples. In terms of results, both the Mann-Whitney U test and the two sample t-test show a significant difference in mean and median for the two samples. Despite the fact that they both could determine whether there are differences between the two sample distributions, the two sample t-test is a more reliable test if only for the fact that the Mann-Whitney U test is better suited for nonnormal distributions (while we transformed our data to become more normal so as to meet the assumption of normality for the t-test). The t-test is a more reliable test compared to its nonparametric analog when the distributions are approximately normal.

## Goodness of Fit Tests

*6. Apply Kolmogorov-Smirnov, Anderson-Darling, Cramer-Von Mises, Shapiro-Wilk Tests for normality to the two samples separately; comment on the findings by comparing results obtained from these four tests. Make a statement about the situation that a particular procedure might be more appropriate. Moreover, based on the results learned here, comment on whether the parametric methods used in (iv) and (v) are appropriate.*  

First, Normality test is sensitive to sample size. Small samples most often pass normality tests. Therefore, it’s important to combine visual inspection and significance test in order to take the right decision.
Second, apply Kolmogorov-Smirnov, Anderson-Darling, Cramer-Von Mises, Shapiro-Wilk Tests for normality as below:

Kolmogorov-Smirnov:
```{r ks.testing, echo = T, include = T}
ks.test(rider_data$bus,"pnorm",mean(rider_data$bus),sd(rider_data$bus))
ks.test(rider_data$rail_boardings,"pnorm",mean(rider_data$rail_boardings),sd(rider_data$rail_boardings))
```
Anderson-Darling:
```{r adarling, echo = T, include = T}
ad.test(rider_data$bus)
ad.test(rider_data$rail_boardings)
```
Cramer-Von Mises:
```{r cvm.test, echo = T, include = T}
cvm.test(rider_data$bus)
cvm.test(rider_data$rail_boardings)
```
Shapiro-Wilk:
```{r sw.test, echo = T, include = T}
shapiro.test(rider_data$bus)
shapiro.test(rider_data$rail_boardings)
```
Comparison of results:
Although all the above methods (Kolmogorov-Smirnov, Anderson-Darling, Cramer-Von Mises, Shapiro-Wilk Tests) have the same result: accept H0 under our sample, the p-value of each test is significantly different which means the measurement for each one is different.

Appropriate situation for the four tests:
Shapiro-Wilk test is the most powerful test for all types of distribution which is customized from Normal whereas Kolmogorov-Smimov test is the least powerful test which perform well only for uniform distribution that don't need boundary. The performance of Anderson-Darling test is quite comparable with Shapiro-Wilk test. Cramer-Von Mises test is an alternative to the Kolmogorov–Smirnov test. However, the power of Shapiro-Wilk test is still low for small sample size.

Kolmogorov-Smimov is based on the empirical distribution function (ECDF), and the maximum distance between these two curves. So, it is indepedent with the underlying cumulative distribution function being tested. But, it is sensitive on the center of the distribution than at the tails.It is suitable for small samples, ties are no problem and has omnibus test, but it is low power if prerequisites are not met.
The Kolmogorov-Smimov test statistic is defined as
$$D = \max_{1 \le i \le N}(F(Y_{i}) - \frac{i} {N}, \frac{i}{N} - F(Y_{i}))$$
And,Cramer-Von Mises test is an alternative to the Kolmogorov–Smirnov test.

Anderson-Darling testis used to test samples with a specific distribution. It is a modification of the Kolmogorov-Smirnov (K-S) test and gives more weight to the tails than does the K-S test which sharpens the test. It is high power when testing for normal distribution but is statistic based on squares.But its critical values must be calculated for each hypothesized distribution.
The Anderson-Darling test statistic is defined as
$$A^{2} = -N - S$$
where
$$S = \sum_{i=1}^{N}\frac{(2i - 1)}{N}[\ln{F(Y_{i})} + \ln{(1 - F(Y_{N+1-i}))}]$$

Shapiro-Wilk test calculates a W statistic that tests whether a random sample, $x_1,x_2,…,x_n$ comes from (specifically) a normal distribution. It is highest power among all tests for normality but test for normality only.
The W statistic is calculated as follows:
$$W = \frac{\left( \sum_{i=1}^n a_i x_{(i)} \right)^2}{\sum_{i=1}^n (x_i - \bar{x})^2}$$
Cramer-Von Mises is higher power than KS test, but it's a statistic based on squares.
Cramer-Von Mises statistic is defined as:
$$U^2 = T-n(\overline{F}-\frac{1}{2})^2$$
where
$$\overline{F} = \frac{1}{n}\sum{F(x_i)}$$
As a result, due to our data is normally distributed and we have more than 300 data points, so in our opinion, it is more reasonable to choose Shapiro-Wilk test.
Because we normalized our ridership data which allows us to be able to perform the parametric F-test and t-test in (iv) and (v).So, in our case, it is appropriate.  

# 2) Multiple-Sample (ANOVA) Studies (60%):  

*Locate one data set each for the two problems below in the field of your interest, e.g., eCommerce, medical study, drug development, supply-chain/logistics operations, for applying the following procedures for ANOVA studies.*  


## Kruskal-Wallis Test  

*1. Apply Kruskal-Wallis Test for an one-way ANOVA study. If it is suitable, perform a K- W pairwise comparisons. Make conclusions about your findings.*  

The Kruskal-Wallis (KW) test is a logical extension of the Wilcoxon-Mann-Whitney  test.  It  is  a  nonparametric  test  used  to  compare  three  or more samples.  It  is  used  to  test  the  null  hypothesis  that  all  populations  have identical distribution functions against the alternative hypothesis that at least two of the samples differ only with respect to location (median), if at all.

We found a dataset relating to red variants of the Portuguese “Vinho Verde” wine. Input variables are 1 - fixed acidity 2 - volatile acidity 3 - citric acid 4 - residual sugar 5 - chlorides 6 - free sulfur dioxide 7 - total sulfur dioxide 8 - density 9 - pH 10 - sulphates 11 - alcohol Output variable (based on sensory data): 12 - quality (score between 0 and 10). 

Data source: 
https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009

Often the quality of wine is attributed to the physical properties like density, color. We can use KW test to check if that is true.

We used 8-density and 12-quality to perform the KW test. 
```{r loadwin, echo = F, include=T}
wdat <- read.csv('data/winequality-red.csv',header = T, stringsAsFactors=F)
kruskal.test(density~quality, data = wdat)
```
  
The result shows that p-value is small enough to reject the null hypothesis, which means density and quality do not have identical distribution functions and therefore aspects other than the physical property also contribute to the quality of wine.

Since the KW test detects the differences of red variants, we can determine if two particular red variants group are different at level alpha. Then we performed a K-W pairwise comparisons to the above dataset. 

```{r posthoccon, echo =F, include = T}
suppressWarnings(suppressMessages(library(PMCMR)))
suppressWarnings(suppressMessages(with(wdat, posthoc.kruskal.conover.test(x = density, g = quality, dist = 'Tukey'))))
```
  
The above test gives us more insight into how density on different qualities relate with each other. In many cases wine of certain quality appears to have similar density as other similar quality wine, like in the case of quality 7 and 8, as well as quality 3 and 4. But for the pairs (5,6) and (6,7) there is good reason the believe that they are unrelated and therefore it may be the case that the seemingly related qualities are just coincidental.  

\newpage  

Here’s the box plot showing the relations of the above data. 

```{r winebox, echo = F, include = T, fig.align='center',fig.height=3}
ggplot(wdat, aes(x = quality, y = density, group = quality)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  scale_x_continuous("Quality Class", labels = as.character(wdat$quality), breaks = wdat$quality) + ggtitle('Boxplot: Density by Wine Quality Classification') + ylab("Density") + theme_bw()
```


The box plot told us that 3-citric acid, 4-residual sugar, 5-chlorides, and 6-free sulfur dioxide are normally distributed. 5-chlorides has lots of outliers. 

## Friedman Test  

*2. Use Friedman test and also the F-Test discussed in the textbook page 148 for the study of one-way ANOVA with one blocking variable. Comment on your findings. If it is suitable, perform a K-W pairwise comparisons. Make conclusions about your findings.*  



## Variance Testing    

*3. Conduct a variance test based on the procedure (Conover test) given in Section 8.3 textbook. Comment on your findings.* 

## Parametric Two Sample Testing 

*4. Repeat the same studies in (i), (ii) and (iii) using parametric approaches (also include the possible pairwise comparisons). State the assumptions needed for the parametric approaches. Compare the results here against those in (i), (ii) and (iii), respectively. Note that if there are certain assumptions (e.g., normality and equal-variance) required in the parametric studies, please apply appropriate procedures to “test” the assumption.*  

