---
title: 'Enrichment Project #1: Rank-based Methods'
date: "`r format(Sys.time(), '%d %B %Y')`"
author:
- Yuan Gao, Kevin Lee, Akshay Govindaraj
- Yijun (Emma) Wan, Peter Williams, Ruixuan Zhang
- ygao390, kylee20, ywan40, agovindaraj6, pwilliams60, rzhang438 | @gatech.edu
output:
  pdf_document: 
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages(library(printr))
suppressPackageStartupMessages(library(conover.test))
suppressPackageStartupMessages(library(car))
suppressPackageStartupMessages(library(nortest))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(reshape2))
```

# 1) Two-sample Studies (40%):
*Locate a data set in the field of your interest, e.g., eCommerce, medical study, drug development, supply-chain/logistics operations, for applying the following procedures for two-sample studies.*  

For our two-sample study, we have selected a dataset published by the City of Chicago Transit Authority (CTA) that details daily ridership numbers (system-wide boarding totals) for both bus and rail services. As a pre-processing step, we take a subset of the original dataset that consists of weekday ridership only (weekends, and holidays excluded) for 2017 and 2018. Below is a quick preview of the dataset and pre-processing steps: 
```{r preview, include=T, echo=F}
rider_data <- read.csv(
  'data/CTA_Ridership_Normalized.csv',
                       header = T,stringsAsFactors = F)
#subset data to just weekdays
rider_data <- rider_data[rider_data$day_type == 'W',]
rider_data <- transform(rider_data, service_date = as.Date(service_date, 
                                                           '%m/%d/%y'))
#subset data to 2017 and 2018 rides only
rider_data <- rider_data[format(rider_data$service_date, '%Y') %in% 
                           c('2017','2018'),]
knitr::kable(head(rider_data,n=5),row.names = F, format.args = list(big.mark = ','))
```
Note: For the purpose of comparison, we transformed the data to normalize the distributions for equal variances between them. This will allow us to perform both nonparametric and parametric tests to determine whether the two sample distributions are different. The variances of the samples were unequal, so we cannot nonparametric tests such as the Wilcoxon Rank Sum Test. With our new data, the variances are close enough that the distributions can then be compared. 

## Bootstrap Re-sampling

*1. Calculate Pearson and Spearman coefficient of correlation and Kendall’s Tau. Use a Bootstrap resampling procedure with B = #bootstrap-samples = 1000 to assess the standard deviation (sd) of three estimates. Comment on your findings.*  

To begin we compute all three statistics using methods in base R, reported here: 
```{r correl, include=T,echo=F}
paste0("Pearson's Correlation: " ,round(with(rider_data, cor(x=bus,y=rail_boardings,
                                                             method = "pearson")),digits=3))
paste0("Spearman's Correlation: " ,round(with(rider_data, cor(x=bus,y=rail_boardings,
                                                              method = "spearman")),digits=3))
paste0("Kendall's Tau: " ,round(with(rider_data, cor(x=bus,y=rail_boardings,
                                                     method = "kendall")),digits=3))
```
We then compute these statistics using $B=1000$ bootstrap samples based on our original dataset, which consists of `r nrow(rider_data)` observations. Code and details are below. As shown in the table of results, bootstrap sample standard deviations for all correlation statistics were similar, and were slightly higher for spearman's rank:  
```{r bstrap, include=T,echo=T, height = 4}
#set the number of bootstrap samples (with replacement - n = 318)
B <- 1000
#replicate process of collecting sample from original dataset, and compute sample stats 
#results stored in: cor_result, with 1000 obs of bootstrap sample stats
#note this process takes a few seconds on a standard laptop
cor_result <- do.call('rbind',lapply(1:B, function(x){
  bootstrap_sample <- rider_data[sample(1:nrow(rider_data),
                                        size=nrow(rider_data), replace=T),]
  data.frame(pearson = cor(bootstrap_sample$bus,bootstrap_sample$rail_boardings, 
                           method = 'pearson'),
             spearman = cor(bootstrap_sample$bus,bootstrap_sample$rail_boardings, 
                            method = 'spearman'),
             kendall = cor(bootstrap_sample$bus,bootstrap_sample$rail_boardings, 
                           method = 'kendall'))
}))
knitr::kable(round(data.frame(lapply(cor_result, sd)),digits=4),row.names=F,
             caption = 'Sample Standard Deviation: Bootstrap Sample Correlation')
```

Density plots of these statistics are shown here, and provide visual evidence that the spearman rank correlation results and kendall's tau have more similar results than the parametric pearson's correlation: 

```{r den_cor, include=T,echo=T,fig.align = 'center',fig.height = 3}
melt_cor_result <- melt(cor_result, measure.vars = c('pearson','spearman','kendall'))
ggplot(melt_cor_result, aes(x = value, fill = variable)) + geom_density(alpha = 0.3) + theme_bw() + 
  xlab('Boostrap Sample Correlation') + ggtitle('Density Plots: Bootstrap Sample Correlations')
```
  
## Signed Rank Tests
*2. Apply Wilcoxon Signed Rank Test, Wilcoxon Sum Rank Test, Mann-Whitney U Test to compare two samples. For each test please state clearly what distribution is used to calculate the p-value.*  

Continuing on with the data given by the CTA on bus and rail ridership in 2017 and 2018, we can attempt to utilize the Wilcoxon Signed-Rank Test to determine whether there is a difference between paired data, but certain assumptions must first be met. In using the Wilcoxon Signed Rank Test, the data must be paired, the pairs must be independent, and the paired differences must be distributed symmetrically about 0 (the assumption that the pairs are drawn from the same population). The samples would also be better if from a nonnormal distribution (comparable parametric tests are more reliable only if data are normally distributed). 

The Signed Rank Test (for two samples) looks at the difference in distributions between paired values, and our data are not paired in this case. Instead, the better test to use in the case of our CTA data would be the Wilcoxon Ranked Sum Test. The goal of the Wilcoxon Ranked Sum Test is to effectively compare two populations with a continuous response variable and nonnormal distributions. Thus, the Wilcoxon Ranked Sum Test is essentially analagous to a nonparametric form of a two sample t-test. Assuming the ridership count between the bus and rail systems are independent of each other and random, we can compare the two samples using the Wilcoxon Ranked Sum Test even without the assumption of paired data as was required in the Wilcoxon Signed Rank Test. 

The Mann Whitney U Test accomplishes essentially the exact same purpose as the Wilcoxon Ranked Sum Test. The only differences are a differently labeled test statistic "U" compared to that of the Wilcoxon ranked sum test statistics "W" as well as the assumption that the shapes of the two population distributions have the same "shape". They are even performed using the exact same function, with the "U" test statistic being equivalent to the "W" test statistics of the Wilcoxson Ranked Sum Test.

```{r histograms_non_normal, echo = T, include = F, fig.align='center',fig.height=3}
#Checking that the distribution of each of the two samples is nonnormal
par(mfrow=c(1,2))
hist(rider_data$bus)
hist(rider_data$rail_boardings)
```
```{r shape_distribution, echo = T, include= T}
#Checking shapes of distributions
par(mfrow=c(1,2))
plot(density(rider_data$bus))
plot(density(
rider_data$rail_boardings))
```
If we plot the density functions and histograms, we can see the distributions seem to resemble normal distributions, and they do resemble each other in terms of their "shape". 

```{r wilcox_rank, echo = T, include = T}
#Performing the Wilcoxon Rank Sum Test/Mann Whitney U Test
wilcox.test(normal_rider$bus, normal_rider$rail_boardings, paired=F)
```

The results of the Wilcoxon Ranked Sum Test show the p-value of the test to be small enough to be significant, meaning we reject the null hypothesis that the distributions of the two samples are identical. The fact that the Wilcoxon Ranked Sum Test and the Mann Whitney U Test are essentially the same test allows us to also state that the medians of the two distributions are also different. 


For the calculation of the p-value, one must first be able to determine the test statistic being used in each test. For the Wilcoxon Rank Sum test, we find the 

$$W_{n} = \sum^{n}_{i=1}iS_{i}(X,Y)$$

where $n_1$ is the sample size of the first sample (observations in bus ridership) , $n_2$ is the sample size of the second sample (observations in rail boarding), and $n_1 + n_2 = n$

$S_{i}$ is an indicator function with value is 1 if ith ranked observation is from the first sample or 0 if from the second sample.
[cite textbook]

The expected value of the W_n statistic is where the distrition will be centered around, and the variance of the statistic will be the symmetrical spread around that center. 

E(W_{n}) = [n_{1}(n+1)]/2

Var(W_{n}) = [n_{1}n_{2}(n+1)]/12

As the test statistic is a linear rank statistic, we can then deduce that the W statistic is distributed approximately normally as long as the sample sizes are large enough (at least 10 observations per sample). We can then calculate the right-tail probability using Z-score with normal approximation with the following distribution:

$$W_{n} ~ N([n_1 (n+1)]/2 , [n_1 (n_2) (n+1)]/12)$$

The Mann-Whitney U statistic is used to calculate p-value much in the same manner of the Wilcoxon Rank Sum Test. The test statistic can be calculated as such: 

$$U = \sum^{n1}_{i=1}\sum^{n2}_{j=1} D_{ij}$$

The test statisic U and W end up becoming the same value, used in the same approximately normal distribution as the W_{n} statistic, which means we can use the same tail probability to find the p-value.

In order to apply the Wilcoxon Signed-Rank Test, we will need to use a different set of data to demonstrate the test in R. For this purpose, we will use the data from this site: https://www.sheffield.ac.uk/polopoly_fs/1.569449!/file/stcp-Rdataset-Video.csv. 
A professor at the University of Sheffield collected data using "Likert" style questions to determine which of three new videos are most effective in informing the public of medical conditions. The four videos in questions are deemed the following: A, a new general video; B, a new medical profession video; C, the old video; and D, a demonstration using props. In this dataset, there are two particular variables of interest, and they are "TotalAGen" and "TotalDDEMO". These two variables are essentially the overall summed "Likert Scores" for each of the different types of videos. Our paired data will be between the scaled overall scores between video A's reception  and video D's reception. 

``` {r sign_rank, echo = T, include= T}
#For performing the Wilcoxon Signed Rank Test, download the dataset
video_data=read.csv('https://www.sheffield.ac.uk/polopoly_fs/1.569449!/file/stcp-Rdataset-Video.csv')
#Wilcoxon Signed Rank Test, with paired data
wilcox.test(video_data$TotalAGen,video_data$TotalDDEMO, paired=T)
#Showing nonnormal distributions of the sample data
hist(video_data$TotalAGen)
hist(video_data$TotalDDEMO)
```

We can assume the independence of each observation (person) as well as the fact that they should come from the same population (differences should be symmetric about 0). The data are also paired, so we can follow through with the test now that the assumptions are met. Through the Wilcoxon Signed Rank Test, we can see that the test statistic V = 167.5, which leads us to a p-value below our assumed alpha level of 0.05. Thus, we can reject the null hypothesis that the two sample distributions (Scores of Video A compared to scores of Video D) are the same. 

The p-value of the signed rank test is based on a W test statistic and tabulated critical values when dealing with lower sample sizes, such that it can be calculated as follows: 

$$W = \sum^{n}_{i=1} sign(x_{2,i}-x_{1,i},|R_i|)$$

Where $R_i$ is the rank of the observation and the statistic is the formula for the sum of the signed ranks. With this test statistic, one can determine a distribution with 

$$E(W) = 0$$
$$Var(T) = [n(n+1)(2n+1)/6]$$ 

where n is the number of non-tied ranked observations. With this information, one can look at a table of set critical values dependent on sample size and quantiles with which to determine whether or not to reject the hypothesis that the

With larger sample sizes though, the distribution of the W statistic for the signed rank test also tends to follow normal approximation, which allows the use of z-score approximation to determine p-value through tail probability.



## Conover Test for Equal Variances
*3. Use Conover test for equal variances in these two samples. Explain how to calculate its p-value.*  

A histogram visualizing the counts of daily bus and rail ridership illustrates that there are likely differences in the variance of daily ridership. Rail ridership tends to be more tightly group around its central point, than bus ridership which is more spread out as shown here: 

```{r histo, include = T, echo=T, fig.align='center',fig.height=3}
boardings <- c(rider_data$bus, rider_data$rail_boardings)
factor_level <- factor(c(rep('bus',nrow(rider_data)), rep('rail',nrow(rider_data))))
ggplot(NULL,aes(x = boardings, fill = factor_level)) + 
  geom_histogram(bins = sqrt(nrow(rider_data)) ) + theme_bw() + 
  ggtitle("Histogram - CTA Daily Boardings by Rail | Bus")
```

To explore this further we utilize the two-sided Conover test to test the hypothesis $H_0: \sigma^2_X = \sigma^2_Y$, where samples $X_1,...,X_{n1}$, and $Y_1,...,Y_{n_2}$ refer to samples from daily ridership of bus and rail. The output of the test utilizing the 'conover.test' function from R is shown below:  

```{r conover, echo =F, include = T}
#alt = 0 -> test hypothesis sigma^2_x \neq sigma^2_y
con_test <- conover.test(x = boardings, g = factor_level,alpha = 0.05, altp = 0, method = 'bonferroni')
con_test
```
  
Since our test statistic $T* =$ `r round(con_test$T,digits=3)`, is outside the region (`r qnorm(0.025)`,`r qnorm(0.975)`), we can reject $H_0$ in favor of the alternative, that is $\sigma^2_{X} \neq \sigma^2_{Y}$. 

The calculation of p-value:
First, the test does not assume that all populations are normally distributed and is recommended when the normality assumption is not viable.
Second, Suppose there are g groups obey normal distribution with possibly different means and standard deviations $\sigma_1, \sigma_2,…, \sigma_g$. Let $n_1, n_2, …, n_g$ denote the number of subjects in each group, $Y_{ki}$ denote response values, and N denote
the total sample size of all groups. The test assumes that the data are obtained by taking a simple random sample from each of the g populations.
The formula for the calculation of Conover test is:

$$T = \frac{1}{D^2}[\sum^{g}_{k=1}\frac{S^2_k}{n_k}-N \overline{S}]$$
Where
$$Z_{ki} = |Y_{ki}-\overline{Y}_k|$$
$$R_{ki} = Rank(Z_{ki})$$
$$S_k = \sum^{n_k}_{i=1}R^2_{ki}$$
$$\overline{S} = \frac{1}{N}\sum^{g}_{k=1}S_k$$
$$D^2 = \frac{1}{N-1}[\sum^{g}_{k=1}\sum^{n_k}_{i=1}R^4_{ki}-N\overline{S}^2]$$
 If the assumptions are met, the distribution of this test statistic follows approximately the Chi-squared distribution with degrees of freedom $g-1$. And then, we can use the p-value of Chi-square distribution to get the p-value of conover test.

## Parametric F-test For Equal Variances

*4. Use the parametric F-test for equal variances to the data; comment on the difference of the assumptions and results compared to them in (iii).*  
F-test for testing equality of variance is used to test the hypothesis of the equality of two population variances.
The test statistic can be obtained by computing the ratio of the two variances $S^2_A$ and $S^2_B$.
$$F=\frac{S^2_A}{S^2_B}$$    
  
The degrees of freedom are $n_A - 1$ (for the numerator) and $n_B - 1$ (for the denominator). And, the more this ratio deviates from $1$, the stronger the evidence for unequal population variances.  

```{r test_var, echo = F, include = T}
var.test(rider_data$bus, rider_data$rail_boardings, alternative = "two.sided")
```
  
The result shows that the p-value $= 0.01772$ which is smaller than our $\alpha = 0.05$. In conclusion, there is significant difference between the two variances.

Assumptions for Conover and F-test:
According to the above, the Conover test does not assume that all populations are normally distributed.
However, F-test is very sensitive to departure from the normal assumption. We use Q-Q plot (quantile-quantile plot) to graphically evaluate the normality of a variable.    

```{r qqplots, echo = F, include = T, fig.align='center',fig.height=4}
#qqnorm(rider_data$bus, pch = 1, frame = FALSE)
#qqline(rider_data$bus, col = "steelblue", lwd = 2)
options(scipen = 999)
par(mfrow = c(1,2))
qqPlot(rider_data$bus, xlab = 'Bus Boardings', main = 'Q-Q Plot - Bus Boardings')
 qqPlot(rider_data$rail, xlab = 'Rail Boardings', main = 'Q-Q Plot - Rail Boardings')
```
As we can see, there are many points don't fall approximately along this reference line, for both rail and bus boardings, so, we cannot assume normality for either sample.

Results for Conover and F-test:
Although the results are consistent based on this sample, Conover test is recommended when the normality assumption is not viable.
As a result, use F-test on the data has shortcomings compared to use Conover test.  

## Parametric Two-Sample T-test

*5. Depending on the outcomes from the F-test in (iv), apply an appropriate parametric two- sample t-test to the data; comment on the difference of the assumptions and results compared to them in (ii).*  

The aim of the two-sample t-test is to find the difference between the two sample means in comparing their respective populations. In utilizing the two sample t-test, some assumptions must first be met. One must assume that the observations of our data are independent of each other, similar to the nonparametric tests. Another such assumption is for the response variable to be continuous, approximately normal distribution. Our normalized ridership data allows us to be able to perform the parametric (pooled) two sample t-test. Similar to the nonparametric tests performed (Mann-Whitney U), the data must be continuous. 

```{r t_test, include = T, echo = F}
#Performing Parametric t-test between the two samples, pooled t-test is used because the normalized data have equal variance.
t.test(rider_data$bus,rider_data$rail_boardings,var.equal=TRUE)
```
  
As we can see from the results of the test, the p-value is quite low, showing that there is a significant difference between the two means. In comparing the two tests, the parametric t-test tests for significance in difference between the means of the two samples, while the nonparametric tests (Mann-Whitney U) test for significance in differences between the distributions (and medians) of the two samples. In terms of results, both the Mann-Whitney U test and the two sample t-test show a significant difference in mean and median for the two samples. Despite the fact that they both could determine whether there are differences between the two sample distributions, the two sample t-test is a more reliable test if only for the fact that the Mann-Whitney U test is better suited for nonnormal distributions (while we transformed our data to become more normal so as to meet the assumption of normality for the t-test). The t-test is a more reliable test compared to its nonparametric analog when the distributions are approximately normal.

## Goodness of Fit Tests

*6. Apply Kolmogorov-Smirnov, Anderson-Darling, Cramer-Von Mises, Shapiro-Wilk Tests for normality to the two samples separately; comment on the findings by comparing results obtained from these four tests. Make a statement about the situation that a particular procedure might be more appropriate. Moreover, based on the results learned here, comment on whether the parametric methods used in (iv) and (v) are appropriate.*  

Kolmogorov-Smirnov:
```{r ks.testing, echo = T, include = T}
ks.test(rider_data$bus,"dnorm",mean(rider_data$bus),sd(rider_data$bus))
ks.test(rider_data$rail_boardings,"dnorm",mean(rider_data$rail_boardings),sd(rider_data$rail_boardings))
```
Anderson-Darling:
```{r adarling, echo = T, include = T}
ad.test(rider_data$bus)
ad.test(rider_data$rail_boardings)
```
Cramer-Von Mises:
```{r cvm.test, echo = T, include = T}
cvm.test(rider_data$bus)
cvm.test(rider_data$rail_boardings)
```
Shapiro-Wilk:
```{r sw.test, echo = T, include = T}
shapiro.test(rider_data$bus)
shapiro.test(rider_data$rail_boardings)
```
Comparison of results:
All the above methods (Kolmogorov-Smirnov, Anderson-Darling, Cramer-Von Mises, Shapiro-Wilk Tests) have the same result: rejest H0 under our sample. But the p-value of each test is significantly different which means the measurement for each one is different.

Appropriate situation for the four tests:
Shapiro-Wilk test is the most powerful test for all types of distribution whereas Kolmogorov-Smimov test is the least powerful test. The performance of Anderson-Darling test is quite comparable with Shapiro-Wilk test. Cramer-Von Mises test is an alternative to the Kolmogorov–Smirnov test. However, the power of Shapiro-Wilk test is still low for small sample size.

Kolmogorov-Smimov is based on the empirical distribution function (ECDF), and the maximum distance between these two curves. So, it is indepedent with the underlying cumulative distribution function being tested. But, it is sensitive on the center of the distribution than at the tails.It is suitable for small samples, ties are no problem and has omnibus test, but it is low power if prerequisites are not met.
The Kolmogorov-Smimov test statistic is defined as
$$D = \max_{1 \le i \le N}(F(Y_{i}) - \frac{i} {N}, \frac{i}{N} - F(Y_{i}))$$

Anderson-Darling testis used to test samples with a specific distribution. It is a modification of the Kolmogorov-Smirnov (K-S) test and gives more weight to the tails than does the K-S test. It is high power when testing for normal distribution but is statistic based on squares.
The Anderson-Darling test statistic is defined as
$$A^{2} = -N - S$$
where
$$S = \sum_{i=1}^{N}\frac{(2i - 1)}{N}[\ln{F(Y_{i})} + \ln{(1 - F(Y_{N+1-i}))}]$$
Shapiro-Wilk test calculates a W statistic that tests whether a random sample, $x_1,x_2,…,x_n$ comes from (specifically) a normal distribution. It is highest power among all tests for normality but test for normality only.
The W statistic is calculated as follows:
$$W = \frac{\left( \sum_{i=1}^n a_i x_{(i)} \right)^2}{\sum_{i=1}^n (x_i - \bar{x})^2}$$
Cramer-Von Mises is higher power than KS test, but it's a statistic based on squares.
Cramer-Von Mises statistic is defined as:
$$U^2 = T-n(\overline{F}-\frac{1}{2})^2$$
where
$$\overline{F} = \frac{1}{n}\sum{F(x_i)}$$
 As a result, due to our data is not normally distributed and we have more than 300 data points, so in our opinion, it is more reasonable to choose Anderson-Darling test.

# 2) Multiple-Sample (ANOVA) Studies (60%):  

*Locate one data set each for the two problems below in the field of your interest, e.g., eCommerce, medical study, drug development, supply-chain/logistics operations, for applying the following procedures for ANOVA studies.*  

## Kruskal-Wallis Test  

*1. Apply Kruskal-Wallis Test for an one-way ANOVA study. If it is suitable, perform a K- W pairwise comparisons. Make conclusions about your findings.*  

## Friedman Test  

*2. Use Friedman test and also the F-Test discussed in the textbook page 148 for the study of one-way ANOVA with one blocking variable. Comment on your findings. If it is suitable, perform a K-W pairwise comparisons. Make conclusions about your findings.*  

## Variance Testing    

*3. Conduct a variance test based on the procedure (Conover test) given in Section 8.3 textbook. Comment on your findings.* 

## Parametric Two Sample Testing 

*4. Repeat the same studies in (i), (ii) and (iii) using parametric approaches (also include the possible pairwise comparisons). State the assumptions needed for the parametric approaches. Compare the results here against those in (i), (ii) and (iii), respectively. Note that if there are certain assumptions (e.g., normality and equal-variance) required in the parametric studies, please apply appropriate procedures to “test” the assumption.*  

